{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"diabetes_012_health_indicators_BRFSS2015.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Diabetes_012', 'HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker',\n",
       "       'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies',\n",
       "       'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth',\n",
       "       'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education',\n",
       "       'Income'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diabetes_012\n",
       "0.0    213703\n",
       "2.0     35346\n",
       "1.0      4631\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Diabetes_012\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8424116997792495"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "213703 / (213703 + 35346 + 4631)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution: Counter({0.0: 213703, 2.0: 35346, 1.0: 4631})\n",
      "Resampled class distribution: Counter({2.0: 149523, 0.0: 149523, 1.0: 149523})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "X = df.drop('Diabetes_012', axis=1)\n",
    "y = df['Diabetes_012']\n",
    "\n",
    "print(f\"Original class distribution: {Counter(y)}\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Display new class distribution after applying SMOTE\n",
    "print(f\"Resampled class distribution: {Counter(y_resampled)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11215/11215 [==============================] - 23s 2ms/step - loss: 0.7735 - accuracy: 0.6289 - val_loss: 0.7016 - val_accuracy: 0.6657\n",
      "Epoch 2/10\n",
      "11215/11215 [==============================] - 22s 2ms/step - loss: 0.6733 - accuracy: 0.6816 - val_loss: 0.6575 - val_accuracy: 0.6914\n",
      "Epoch 3/10\n",
      "11215/11215 [==============================] - 21s 2ms/step - loss: 0.6338 - accuracy: 0.7043 - val_loss: 0.6296 - val_accuracy: 0.7052\n",
      "Epoch 4/10\n",
      "11215/11215 [==============================] - 24s 2ms/step - loss: 0.6037 - accuracy: 0.7213 - val_loss: 0.5983 - val_accuracy: 0.7230\n",
      "Epoch 5/10\n",
      "11215/11215 [==============================] - 24s 2ms/step - loss: 0.5794 - accuracy: 0.7352 - val_loss: 0.5726 - val_accuracy: 0.7376\n",
      "Epoch 6/10\n",
      "11215/11215 [==============================] - 25s 2ms/step - loss: 0.5590 - accuracy: 0.7464 - val_loss: 0.5599 - val_accuracy: 0.7445\n",
      "Epoch 7/10\n",
      "11215/11215 [==============================] - 22s 2ms/step - loss: 0.5413 - accuracy: 0.7558 - val_loss: 0.5601 - val_accuracy: 0.7442\n",
      "Epoch 8/10\n",
      "11215/11215 [==============================] - 24s 2ms/step - loss: 0.5269 - accuracy: 0.7634 - val_loss: 0.5613 - val_accuracy: 0.7437\n",
      "Epoch 9/10\n",
      "11215/11215 [==============================] - 25s 2ms/step - loss: 0.5117 - accuracy: 0.7707 - val_loss: 0.5397 - val_accuracy: 0.7576\n",
      "Epoch 10/10\n",
      "11215/11215 [==============================] - 23s 2ms/step - loss: 0.5004 - accuracy: 0.7774 - val_loss: 0.5259 - val_accuracy: 0.7625\n",
      "2804/2804 [==============================] - 4s 1ms/step - loss: 0.5259 - accuracy: 0.7625\n",
      "Test Accuracy: 0.7625\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Build the DNN model\n",
    "model = Sequential([\n",
    "    Dense(32, input_dim=X_train.shape[1], activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(3, activation='softmax')  # Output layer for multi-class classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "11215/11215 [==============================] - 14s 1ms/step - loss: 0.7297 - accuracy: 0.6548 - val_loss: 0.6540 - val_accuracy: 0.6945\n",
      "Epoch 2/10\n",
      "11215/11215 [==============================] - 13s 1ms/step - loss: 0.6160 - accuracy: 0.7178 - val_loss: 0.5798 - val_accuracy: 0.7354\n",
      "Epoch 3/10\n",
      "11215/11215 [==============================] - 13s 1ms/step - loss: 0.5621 - accuracy: 0.7481 - val_loss: 0.5407 - val_accuracy: 0.7582\n",
      "Epoch 4/10\n",
      "11215/11215 [==============================] - 13s 1ms/step - loss: 0.5232 - accuracy: 0.7685 - val_loss: 0.5380 - val_accuracy: 0.7646\n",
      "Epoch 5/10\n",
      "11215/11215 [==============================] - 13s 1ms/step - loss: 0.4943 - accuracy: 0.7830 - val_loss: 0.4977 - val_accuracy: 0.7828\n",
      "Epoch 6/10\n",
      "11215/11215 [==============================] - 14s 1ms/step - loss: 0.4699 - accuracy: 0.7944 - val_loss: 0.4707 - val_accuracy: 0.7942\n",
      "Epoch 7/10\n",
      "11215/11215 [==============================] - 13s 1ms/step - loss: 0.4528 - accuracy: 0.8029 - val_loss: 0.4667 - val_accuracy: 0.7960\n",
      "Epoch 8/10\n",
      "11215/11215 [==============================] - 13s 1ms/step - loss: 0.4383 - accuracy: 0.8093 - val_loss: 0.4476 - val_accuracy: 0.8041\n",
      "Epoch 9/10\n",
      "11215/11215 [==============================] - 13s 1ms/step - loss: 0.4251 - accuracy: 0.8155 - val_loss: 0.4414 - val_accuracy: 0.8100\n",
      "Epoch 10/10\n",
      "11215/11215 [==============================] - 14s 1ms/step - loss: 0.4130 - accuracy: 0.8205 - val_loss: 0.4369 - val_accuracy: 0.8107\n",
      "2804/2804 [==============================] - 2s 808us/step - loss: 0.4369 - accuracy: 0.8107\n",
      "Model Accuracy: 0.8107\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y = to_categorical(y, num_classes=3)\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "def build_custom_model(input_shape):\n",
    "    # Input layer\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Branch 1: Handling physical health-related features\n",
    "    x1 = Dense(64, activation='relu')(inputs)\n",
    "    x1 = Dense(16, activation='relu')(x1)\n",
    "    \n",
    "    # Branch 2: Handling lifestyle-related features\n",
    "    x2 = Dense(64, activation='relu')(inputs)\n",
    "    x2 = Dense(16, activation='relu')(x2)\n",
    "    \n",
    "    # Branch 3: Handling demographic features\n",
    "    x3 = Dense(64, activation='relu')(inputs)\n",
    "    x3 = Dense(16, activation='relu')(x3)\n",
    "    \n",
    "    # Combine branches\n",
    "    combined = Concatenate()([x1, x2, x3])\n",
    "    \n",
    "    # Fully connected layers\n",
    "    x = Dense(128, activation='relu')(combined)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    outputs = Dense(3, activation='softmax')(x)\n",
    "    \n",
    "    # Build model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_custom_model((X_train.shape[1], ))\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "6342/6342 [==============================] - 9s 1ms/step - loss: 0.4012 - accuracy: 0.8471 - val_loss: 0.3953 - val_accuracy: 0.8497\n",
      "Epoch 2/10\n",
      "6342/6342 [==============================] - 8s 1ms/step - loss: 0.3961 - accuracy: 0.8490 - val_loss: 0.3916 - val_accuracy: 0.8492\n",
      "Epoch 3/10\n",
      "6342/6342 [==============================] - 8s 1ms/step - loss: 0.3948 - accuracy: 0.8494 - val_loss: 0.3948 - val_accuracy: 0.8455\n",
      "Epoch 4/10\n",
      "6342/6342 [==============================] - 8s 1ms/step - loss: 0.3938 - accuracy: 0.8497 - val_loss: 0.3928 - val_accuracy: 0.8505\n",
      "Epoch 5/10\n",
      "6342/6342 [==============================] - 9s 1ms/step - loss: 0.3928 - accuracy: 0.8500 - val_loss: 0.3934 - val_accuracy: 0.8479\n",
      "Epoch 6/10\n",
      "6342/6342 [==============================] - 9s 1ms/step - loss: 0.3917 - accuracy: 0.8508 - val_loss: 0.3919 - val_accuracy: 0.8510\n",
      "Epoch 7/10\n",
      "6342/6342 [==============================] - 8s 1ms/step - loss: 0.3908 - accuracy: 0.8507 - val_loss: 0.3953 - val_accuracy: 0.8480\n",
      "Epoch 8/10\n",
      "6342/6342 [==============================] - 8s 1ms/step - loss: 0.3898 - accuracy: 0.8515 - val_loss: 0.3922 - val_accuracy: 0.8494\n",
      "Epoch 9/10\n",
      "6342/6342 [==============================] - 9s 1ms/step - loss: 0.3887 - accuracy: 0.8518 - val_loss: 0.3922 - val_accuracy: 0.8497\n",
      "Epoch 10/10\n",
      "6342/6342 [==============================] - 8s 1ms/step - loss: 0.3877 - accuracy: 0.8526 - val_loss: 0.3930 - val_accuracy: 0.8497\n",
      "1586/1586 [==============================] - 1s 830us/step - loss: 0.3930 - accuracy: 0.8497\n",
      "Model Accuracy: 0.8497\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y = to_categorical(y, num_classes=3)\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "def build_custom_model(input_shape):\n",
    "    # Input layer\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Branch 1: Handling physical health-related features\n",
    "    x1 = Dense(128, activation='relu')(inputs)\n",
    "    x1 = Dense(64, activation='relu')(x1)\n",
    "    \n",
    "    # Branch 2: Handling lifestyle-related features\n",
    "    x2 = Dense(128, activation='relu')(inputs)\n",
    "    x2 = Dense(64, activation='relu')(x2)\n",
    "    \n",
    "    # Branch 3: Handling demographic features\n",
    "    x3 = Dense(128, activation='relu')(inputs)\n",
    "    x3 = Dense(64, activation='relu')(x3)\n",
    "    \n",
    "    # Combine branches\n",
    "    combined = Concatenate()([x1, x2, x3])\n",
    "    \n",
    "    # Fully connected layers\n",
    "    x = Dense(128, activation='relu')(combined)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    outputs = Dense(3, activation='softmax')(x)\n",
    "    \n",
    "    # Build model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_custom_model((X_train.shape[1], ))\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "11215/11215 [==============================] - 18s 1ms/step - loss: 0.7038 - accuracy: 0.6708 - val_loss: 0.6227 - val_accuracy: 0.7199\n",
      "Epoch 2/10\n",
      "11215/11215 [==============================] - 16s 1ms/step - loss: 0.5423 - accuracy: 0.7604 - val_loss: 0.4939 - val_accuracy: 0.7828\n",
      "Epoch 3/10\n",
      "11215/11215 [==============================] - 16s 1ms/step - loss: 0.4631 - accuracy: 0.7993 - val_loss: 0.4410 - val_accuracy: 0.8100\n",
      "Epoch 4/10\n",
      "11215/11215 [==============================] - 16s 1ms/step - loss: 0.4137 - accuracy: 0.8216 - val_loss: 0.4221 - val_accuracy: 0.8193\n",
      "Epoch 5/10\n",
      "11215/11215 [==============================] - 17s 2ms/step - loss: 0.3812 - accuracy: 0.8356 - val_loss: 0.3901 - val_accuracy: 0.8321\n",
      "Epoch 6/10\n",
      "11215/11215 [==============================] - 16s 1ms/step - loss: 0.3568 - accuracy: 0.8460 - val_loss: 0.3652 - val_accuracy: 0.8440\n",
      "Epoch 7/10\n",
      "11215/11215 [==============================] - 16s 1ms/step - loss: 0.3382 - accuracy: 0.8546 - val_loss: 0.3518 - val_accuracy: 0.8512\n",
      "Epoch 8/10\n",
      "11215/11215 [==============================] - 16s 1ms/step - loss: 0.3233 - accuracy: 0.8609 - val_loss: 0.3419 - val_accuracy: 0.8541\n",
      "Epoch 9/10\n",
      "11215/11215 [==============================] - 17s 1ms/step - loss: 0.3106 - accuracy: 0.8656 - val_loss: 0.3371 - val_accuracy: 0.8583\n",
      "Epoch 10/10\n",
      "11215/11215 [==============================] - 17s 2ms/step - loss: 0.3011 - accuracy: 0.8698 - val_loss: 0.3297 - val_accuracy: 0.8599\n",
      "2804/2804 [==============================] - 3s 901us/step - loss: 0.3297 - accuracy: 0.8599\n",
      "Model Accuracy: 0.8599\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y = to_categorical(y, num_classes=3)\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "def build_custom_model(input_shape):\n",
    "    # Input layer\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Branch 1: Handling physical health-related features\n",
    "    x1 = Dense(128, activation='relu')(inputs)\n",
    "    x1 = Dense(128, activation='relu')(x1)\n",
    "    x1 = Dense(64, activation='relu')(x1)\n",
    "    \n",
    "    # Branch 2: Handling lifestyle-related features\n",
    "    x2 = Dense(128, activation='relu')(inputs)\n",
    "    x2 = Dense(128, activation='relu')(x2)\n",
    "    x2 = Dense(64, activation='relu')(x2)\n",
    "    \n",
    "    # Branch 3: Handling demographic features\n",
    "    x3 = Dense(128, activation='relu')(inputs)\n",
    "    x3 = Dense(128, activation='relu')(x2)\n",
    "    x3 = Dense(64, activation='relu')(x3)\n",
    "    \n",
    "    # Combine branches\n",
    "    combined = Concatenate()([x1, x2, x3])\n",
    "    \n",
    "    # Fully connected layers\n",
    "    x = Dense(128, activation='relu')(combined)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    outputs = Dense(3, activation='softmax')(x)\n",
    "    \n",
    "    # Build model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_custom_model((X_train.shape[1], ))\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "5608/5608 [==============================] - 11s 2ms/step - loss: 0.7041 - accuracy: 0.6709 - val_loss: 0.6157 - val_accuracy: 0.7244\n",
      "Epoch 2/40\n",
      "5608/5608 [==============================] - 11s 2ms/step - loss: 0.5370 - accuracy: 0.7632 - val_loss: 0.5049 - val_accuracy: 0.7799\n",
      "Epoch 3/40\n",
      "5608/5608 [==============================] - 10s 2ms/step - loss: 0.4548 - accuracy: 0.8029 - val_loss: 0.4343 - val_accuracy: 0.8127\n",
      "Epoch 4/40\n",
      "5608/5608 [==============================] - 10s 2ms/step - loss: 0.4060 - accuracy: 0.8245 - val_loss: 0.4044 - val_accuracy: 0.8247\n",
      "Epoch 5/40\n",
      "5608/5608 [==============================] - 10s 2ms/step - loss: 0.3753 - accuracy: 0.8388 - val_loss: 0.3998 - val_accuracy: 0.8291\n",
      "Epoch 6/40\n",
      "5608/5608 [==============================] - 10s 2ms/step - loss: 0.3486 - accuracy: 0.8496 - val_loss: 0.3656 - val_accuracy: 0.8416\n",
      "Epoch 7/40\n",
      "5608/5608 [==============================] - 10s 2ms/step - loss: 0.3309 - accuracy: 0.8573 - val_loss: 0.3520 - val_accuracy: 0.8468\n",
      "Epoch 8/40\n",
      "5608/5608 [==============================] - 10s 2ms/step - loss: 0.3159 - accuracy: 0.8629 - val_loss: 0.3422 - val_accuracy: 0.8542\n",
      "Epoch 9/40\n",
      "5608/5608 [==============================] - 10s 2ms/step - loss: 0.3031 - accuracy: 0.8684 - val_loss: 0.3315 - val_accuracy: 0.8576\n",
      "Epoch 10/40\n",
      "5608/5608 [==============================] - 10s 2ms/step - loss: 0.2924 - accuracy: 0.8735 - val_loss: 0.3184 - val_accuracy: 0.8615\n",
      "Epoch 11/40\n",
      "5608/5608 [==============================] - 10s 2ms/step - loss: 0.2833 - accuracy: 0.8770 - val_loss: 0.3139 - val_accuracy: 0.8647\n",
      "Epoch 12/40\n",
      "5608/5608 [==============================] - 10s 2ms/step - loss: 0.2753 - accuracy: 0.8800 - val_loss: 0.3149 - val_accuracy: 0.8653\n",
      "Epoch 13/40\n",
      "5608/5608 [==============================] - 10s 2ms/step - loss: 0.2679 - accuracy: 0.8835 - val_loss: 0.3000 - val_accuracy: 0.8708\n",
      "Epoch 14/40\n",
      "5608/5608 [==============================] - 10s 2ms/step - loss: 0.2620 - accuracy: 0.8858 - val_loss: 0.3134 - val_accuracy: 0.8662\n",
      "Epoch 15/40\n",
      "5608/5608 [==============================] - 10s 2ms/step - loss: 0.2562 - accuracy: 0.8883 - val_loss: 0.2990 - val_accuracy: 0.8737\n",
      "Epoch 16/40\n",
      "5608/5608 [==============================] - 10s 2ms/step - loss: 0.2516 - accuracy: 0.8905 - val_loss: 0.3096 - val_accuracy: 0.8698\n",
      "Epoch 17/40\n",
      "5608/5608 [==============================] - 10s 2ms/step - loss: 0.2456 - accuracy: 0.8934 - val_loss: 0.2994 - val_accuracy: 0.8734\n",
      "Epoch 18/40\n",
      "5608/5608 [==============================] - 9s 2ms/step - loss: 0.2409 - accuracy: 0.8949 - val_loss: 0.2917 - val_accuracy: 0.8783\n",
      "Epoch 19/40\n",
      "5608/5608 [==============================] - 9s 2ms/step - loss: 0.2368 - accuracy: 0.8972 - val_loss: 0.2949 - val_accuracy: 0.8766\n",
      "Epoch 20/40\n",
      "5608/5608 [==============================] - 9s 2ms/step - loss: 0.2335 - accuracy: 0.8980 - val_loss: 0.2906 - val_accuracy: 0.8778\n",
      "Epoch 21/40\n",
      "5608/5608 [==============================] - 9s 2ms/step - loss: 0.2289 - accuracy: 0.9003 - val_loss: 0.2890 - val_accuracy: 0.8781\n",
      "Epoch 22/40\n",
      "5608/5608 [==============================] - 9s 2ms/step - loss: 0.2257 - accuracy: 0.9021 - val_loss: 0.2909 - val_accuracy: 0.8772\n",
      "Epoch 23/40\n",
      "5608/5608 [==============================] - 9s 2ms/step - loss: 0.2222 - accuracy: 0.9032 - val_loss: 0.2982 - val_accuracy: 0.8751\n",
      "Epoch 24/40\n",
      "5608/5608 [==============================] - 9s 2ms/step - loss: 0.2199 - accuracy: 0.9043 - val_loss: 0.2808 - val_accuracy: 0.8814\n",
      "Epoch 25/40\n",
      "5608/5608 [==============================] - 9s 2ms/step - loss: 0.2155 - accuracy: 0.9061 - val_loss: 0.2774 - val_accuracy: 0.8844\n",
      "Epoch 26/40\n",
      "5608/5608 [==============================] - 9s 2ms/step - loss: 0.2140 - accuracy: 0.9073 - val_loss: 0.2739 - val_accuracy: 0.8849\n",
      "Epoch 27/40\n",
      "5608/5608 [==============================] - 9s 2ms/step - loss: 0.2107 - accuracy: 0.9088 - val_loss: 0.2801 - val_accuracy: 0.8817\n",
      "Epoch 28/40\n",
      "5608/5608 [==============================] - 9s 2ms/step - loss: 0.2073 - accuracy: 0.9100 - val_loss: 0.2757 - val_accuracy: 0.8861\n",
      "Epoch 29/40\n",
      "5608/5608 [==============================] - 9s 2ms/step - loss: 0.2058 - accuracy: 0.9113 - val_loss: 0.2849 - val_accuracy: 0.8862\n",
      "Epoch 30/40\n",
      "5608/5608 [==============================] - 9s 2ms/step - loss: 0.2031 - accuracy: 0.9123 - val_loss: 0.2866 - val_accuracy: 0.8840\n",
      "Epoch 31/40\n",
      "5608/5608 [==============================] - 9s 2ms/step - loss: 0.2017 - accuracy: 0.9124 - val_loss: 0.2935 - val_accuracy: 0.8822\n",
      "Epoch 32/40\n",
      "5608/5608 [==============================] - 9s 2ms/step - loss: 0.1995 - accuracy: 0.9138 - val_loss: 0.2854 - val_accuracy: 0.8838\n",
      "Epoch 33/40\n",
      "5608/5608 [==============================] - 9s 2ms/step - loss: 0.1972 - accuracy: 0.9149 - val_loss: 0.2781 - val_accuracy: 0.8867\n",
      "Epoch 34/40\n",
      "5608/5608 [==============================] - 9s 2ms/step - loss: 0.1949 - accuracy: 0.9163 - val_loss: 0.2776 - val_accuracy: 0.8898\n",
      "Epoch 35/40\n",
      "5608/5608 [==============================] - 9s 2ms/step - loss: 0.1927 - accuracy: 0.9170 - val_loss: 0.3021 - val_accuracy: 0.8856\n",
      "Epoch 36/40\n",
      "5608/5608 [==============================] - 9s 2ms/step - loss: 0.1914 - accuracy: 0.9178 - val_loss: 0.2775 - val_accuracy: 0.8881\n",
      "Epoch 37/40\n",
      "5608/5608 [==============================] - 9s 2ms/step - loss: 0.1887 - accuracy: 0.9191 - val_loss: 0.2745 - val_accuracy: 0.8897\n",
      "Epoch 38/40\n",
      "5608/5608 [==============================] - 9s 2ms/step - loss: 0.1879 - accuracy: 0.9194 - val_loss: 0.3019 - val_accuracy: 0.8857\n",
      "Epoch 39/40\n",
      "5608/5608 [==============================] - 9s 2ms/step - loss: 0.1859 - accuracy: 0.9202 - val_loss: 0.2951 - val_accuracy: 0.8816\n",
      "Epoch 40/40\n",
      "5608/5608 [==============================] - 9s 2ms/step - loss: 0.1839 - accuracy: 0.9213 - val_loss: 0.2874 - val_accuracy: 0.8899\n",
      "2804/2804 [==============================] - 2s 870us/step - loss: 0.2874 - accuracy: 0.8899\n",
      "Model Accuracy: 0.8899\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def build_custom_model(input_shape):\n",
    "    # Input layer\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Branch 1: Handling physical health-related features\n",
    "    x1 = Dense(128, activation='relu')(inputs)\n",
    "    x1 = Dense(128, activation='relu')(x1)\n",
    "    x1 = Dense(64, activation='relu')(x1)\n",
    "    \n",
    "    # Branch 2: Handling lifestyle-related features\n",
    "    x2 = Dense(128, activation='relu')(inputs)\n",
    "    x2 = Dense(128, activation='relu')(x2)\n",
    "    x2 = Dense(64, activation='relu')(x2)\n",
    "    \n",
    "    # Branch 3: Handling demographic features\n",
    "    x3 = Dense(128, activation='relu')(inputs)\n",
    "    x3 = Dense(128, activation='relu')(x2)\n",
    "    x3 = Dense(64, activation='relu')(x3)\n",
    "    \n",
    "    # Combine branches\n",
    "    combined = Concatenate()([x1, x2, x3])\n",
    "    \n",
    "    # Fully connected layers\n",
    "    x = Dense(128, activation='relu')(combined)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    outputs = Dense(3, activation='softmax')(x)\n",
    "    \n",
    "    # Build model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_custom_model((X_train.shape[1], ))\n",
    "\n",
    "model.fit(X_train, y_train, epochs=16, batch_size=64, validation_data=(X_test, y_test))\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "5608/5608 [==============================] - 12s 2ms/step - loss: 0.6804 - accuracy: 0.6871 - val_loss: 0.5425 - val_accuracy: 0.7614\n",
      "Epoch 2/16\n",
      "5608/5608 [==============================] - 11s 2ms/step - loss: 0.4847 - accuracy: 0.7892 - val_loss: 0.4608 - val_accuracy: 0.7960\n",
      "Epoch 3/16\n",
      "5608/5608 [==============================] - 11s 2ms/step - loss: 0.4005 - accuracy: 0.8276 - val_loss: 0.3785 - val_accuracy: 0.8367\n",
      "Epoch 4/16\n",
      "5608/5608 [==============================] - 12s 2ms/step - loss: 0.3539 - accuracy: 0.8479 - val_loss: 0.3662 - val_accuracy: 0.8429\n",
      "Epoch 5/16\n",
      "5608/5608 [==============================] - 11s 2ms/step - loss: 0.3245 - accuracy: 0.8606 - val_loss: 0.3281 - val_accuracy: 0.8587\n",
      "Epoch 6/16\n",
      "5608/5608 [==============================] - 11s 2ms/step - loss: 0.3030 - accuracy: 0.8695 - val_loss: 0.3156 - val_accuracy: 0.8641\n",
      "Epoch 7/16\n",
      "5608/5608 [==============================] - 12s 2ms/step - loss: 0.2850 - accuracy: 0.8772 - val_loss: 0.3153 - val_accuracy: 0.8662\n",
      "Epoch 8/16\n",
      "5608/5608 [==============================] - 12s 2ms/step - loss: 0.2720 - accuracy: 0.8826 - val_loss: 0.3028 - val_accuracy: 0.8680\n",
      "Epoch 9/16\n",
      "5608/5608 [==============================] - 11s 2ms/step - loss: 0.2594 - accuracy: 0.8875 - val_loss: 0.2917 - val_accuracy: 0.8740\n",
      "Epoch 10/16\n",
      "5608/5608 [==============================] - 11s 2ms/step - loss: 0.2506 - accuracy: 0.8913 - val_loss: 0.2905 - val_accuracy: 0.8754\n",
      "Epoch 11/16\n",
      "5608/5608 [==============================] - 12s 2ms/step - loss: 0.2421 - accuracy: 0.8955 - val_loss: 0.2850 - val_accuracy: 0.8798\n",
      "Epoch 12/16\n",
      "5608/5608 [==============================] - 12s 2ms/step - loss: 0.2343 - accuracy: 0.8991 - val_loss: 0.2819 - val_accuracy: 0.8812\n",
      "Epoch 13/16\n",
      "5608/5608 [==============================] - 12s 2ms/step - loss: 0.2277 - accuracy: 0.9017 - val_loss: 0.2746 - val_accuracy: 0.8825\n",
      "Epoch 14/16\n",
      "5608/5608 [==============================] - 11s 2ms/step - loss: 0.2204 - accuracy: 0.9058 - val_loss: 0.2781 - val_accuracy: 0.8834\n",
      "Epoch 15/16\n",
      "5608/5608 [==============================] - 11s 2ms/step - loss: 0.2149 - accuracy: 0.9077 - val_loss: 0.2699 - val_accuracy: 0.8861\n",
      "Epoch 16/16\n",
      "5608/5608 [==============================] - 11s 2ms/step - loss: 0.2085 - accuracy: 0.9112 - val_loss: 0.2717 - val_accuracy: 0.8894\n",
      "2804/2804 [==============================] - 3s 966us/step - loss: 0.2717 - accuracy: 0.8894\n",
      "Model Accuracy: 0.8894\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def build_custom_model(input_shape):\n",
    "    # Input layer\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Branch 1: Handling physical health-related features\n",
    "    x1 = Dense(128, activation='relu')(inputs)\n",
    "    x1 = Dense(128, activation='relu')(x1)\n",
    "    x1 = Dense(64, activation='relu')(x1)\n",
    "    \n",
    "    # Branch 2: Handling lifestyle-related features\n",
    "    x2 = Dense(128, activation='relu')(inputs)\n",
    "    x2 = Dense(128, activation='relu')(x2)\n",
    "    x2 = Dense(64, activation='relu')(x2)\n",
    "    \n",
    "    # Branch 3: Handling demographic features\n",
    "    x3 = Dense(128, activation='relu')(inputs)\n",
    "    x3 = Dense(128, activation='relu')(x3)\n",
    "    x3 = Dense(64, activation='relu')(x3)\n",
    "    \n",
    "    x4 = Dense(128, activation='relu')(inputs)\n",
    "    x4 = Dense(128, activation='relu')(x4)\n",
    "    x4 = Dense(64, activation='relu')(x4)\n",
    "\n",
    "    # Combine branches\n",
    "    combined = Concatenate()([x1, x2, x3, x4])\n",
    "    \n",
    "    # Fully connected layers\n",
    "    x = Dense(128, activation='relu')(combined)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    outputs = Dense(3, activation='softmax')(x)\n",
    "    \n",
    "    # Build model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_custom_model((X_train.shape[1], ))\n",
    "\n",
    "model.fit(X_train, y_train, epochs=16, batch_size=64, validation_data=(X_test, y_test))\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
